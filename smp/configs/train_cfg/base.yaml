# configs/train_cfg/base.yaml

# You can experiment with changing the optimizer or scheduler.
# Basically, it monitors avg_dice_score.
# Pay attention to the ealrystop patience argument. \
# It is related to the validation interval.

optimizer:
  name: Adam
  lr_backbone: 1e-5
  params:
    lr: 1e-4
    weight_decay: 1e-6

scheduler:
  name: CosineAnnealingWarmRestarts 
  params:
    T_0: 100            # epoch (1 cycle)
    T_mult: 2           # It decreases by 1/2 per cycle. (next cycle: T_0/2)
    eta_min: 0.000001   # 1e-6

trainer:
  max_epochs: 300
  check_val_every_n_epoch: 5    # validation interval
  accelerator: gpu
  devices: 1

callbacks:
  earlystopping:
    enabled: True
    params:
      monitor: avg_dice_score
      patience: 5               # validation interval * patience (25 patience)
      mode: max
  model_checkpoint:
    enabled: True
    params:
      monitor: avg_dice_score
      save_top_k: 3             # save top 3 weights in your logs dir (/checkpoints)
      mode: max

logger:
  tensorboard: True
  wandb: True                   # To use the wandb logger, you must init it first.
  project: arch                 # {unetplusplus}
  name: encoder_experiments     # {efficientnet-b7}_{rotate_aug_test}
